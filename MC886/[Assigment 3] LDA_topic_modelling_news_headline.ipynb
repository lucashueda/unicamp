{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA topic modelling news headline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgWP3u01PCiO",
        "colab_type": "text"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y52GWNOHdlyw",
        "colab_type": "code",
        "outputId": "ff1b5404-9985-4674-81ec-9881fa791bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Importing libs to text manipulation\n",
        "import gensim\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "# You will have to download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim import corpora, models\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import gc\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTe-O762OtBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Jupyter COLAB/MC886/Assigment 3/news_headlines.csv', encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bisfj6TAPAp7",
        "colab_type": "code",
        "outputId": "861412ff-ff50-4f57-9ff3-647ac99ec4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030303</td>\n",
              "      <td>unhooked brakes to blame for taiwan train disa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030918</td>\n",
              "      <td>oldest prisoner in tas released citing health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030913</td>\n",
              "      <td>nine reportedly dead in portuguese plane crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20031031</td>\n",
              "      <td>nurses welcome medicare rebate plan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030930</td>\n",
              "      <td>un cuts its iraq staff</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030303  unhooked brakes to blame for taiwan train disa...\n",
              "1      20030918      oldest prisoner in tas released citing health\n",
              "2      20030913     nine reportedly dead in portuguese plane crash\n",
              "3      20031031                nurses welcome medicare rebate plan\n",
              "4      20030930                             un cuts its iraq staff"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2UoEuHCSmtk",
        "colab_type": "text"
      },
      "source": [
        "# First lets create Day, Month  and Year variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-XWFAGScfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['str_publish_date'] = df['publish_date'].astype(str)\n",
        "\n",
        "df['year'] = df['str_publish_date'].apply(lambda x: int(x[:4]))\n",
        "df['month'] = df['str_publish_date'].apply(lambda x: int(x[4:6]))\n",
        "df['day'] = df['str_publish_date'].apply(lambda x: int(x[6:8]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2IHajvqSzIL",
        "colab_type": "code",
        "outputId": "77645a9d-4ff1-4d85-a378-ee5c51bfa219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>str_publish_date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030303</td>\n",
              "      <td>unhooked brakes to blame for taiwan train disa...</td>\n",
              "      <td>20030303</td>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030918</td>\n",
              "      <td>oldest prisoner in tas released citing health</td>\n",
              "      <td>20030918</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030913</td>\n",
              "      <td>nine reportedly dead in portuguese plane crash</td>\n",
              "      <td>20030913</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20031031</td>\n",
              "      <td>nurses welcome medicare rebate plan</td>\n",
              "      <td>20031031</td>\n",
              "      <td>2003</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030930</td>\n",
              "      <td>un cuts its iraq staff</td>\n",
              "      <td>20030930</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text  ... month  day\n",
              "0      20030303  unhooked brakes to blame for taiwan train disa...  ...     3    3\n",
              "1      20030918      oldest prisoner in tas released citing health  ...     9   18\n",
              "2      20030913     nine reportedly dead in portuguese plane crash  ...     9   13\n",
              "3      20031031                nurses welcome medicare rebate plan  ...    10   31\n",
              "4      20030930                             un cuts its iraq staff  ...     9   30\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ertRSHsTgUA",
        "colab_type": "text"
      },
      "source": [
        "# How many news we have by years?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m9u5GhpTWYv",
        "colab_type": "code",
        "outputId": "adb8b4e9-ceb4-4ef7-88ca-33e115ad377e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df.groupby('year').agg({'day':'count'}).reset_index().rename(columns = {'day':'count'})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2003</td>\n",
              "      <td>59343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004</td>\n",
              "      <td>65975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005</td>\n",
              "      <td>66320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006</td>\n",
              "      <td>61568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007</td>\n",
              "      <td>69431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2008</td>\n",
              "      <td>71591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2009</td>\n",
              "      <td>68867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2010</td>\n",
              "      <td>67715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011</td>\n",
              "      <td>69919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2012</td>\n",
              "      <td>78547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2013</td>\n",
              "      <td>81016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2014</td>\n",
              "      <td>73361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2015</td>\n",
              "      <td>70004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2016</td>\n",
              "      <td>52162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2017</td>\n",
              "      <td>44182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    year  count\n",
              "0   2003  59343\n",
              "1   2004  65975\n",
              "2   2005  66320\n",
              "3   2006  61568\n",
              "4   2007  69431\n",
              "5   2008  71591\n",
              "6   2009  68867\n",
              "7   2010  67715\n",
              "8   2011  69919\n",
              "9   2012  78547\n",
              "10  2013  81016\n",
              "11  2014  73361\n",
              "12  2015  70004\n",
              "13  2016  52162\n",
              "14  2017  44182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx9OaKhgUCsO",
        "colab_type": "text"
      },
      "source": [
        "# Lets apply some text preprocessing\n",
        "\n",
        "- lower case\n",
        "- remove ponctuation\n",
        "- remove stopwords\n",
        "- lemmatize\n",
        "- stemmize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF4nYIDEUtH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First lets take all text to lower case\n",
        "\n",
        "df['headline_text'] = df['headline_text'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIqsOIuzfS_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets remove all ponctuations\n",
        "\n",
        "df['headline_text'] = df['headline_text'].str.replace('[{}]'.format(string.punctuation), '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQg-nKaXflIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing stopwords by tokenizing removing them and join the text again\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def tokenize(string_series):\n",
        "  return list(gensim.utils.tokenize(string_series))\n",
        "\n",
        "def join_tokens(tokens):\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "def remove_sw(string_series,stopwords):\n",
        "  \n",
        "  tokens = tokenize(string_series)\n",
        "  no_sw = [w for w in tokens if w not in stopwords]\n",
        "  result = join_tokens(no_sw)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MO5VPNEggBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying the function\n",
        "\n",
        "df['new_headline_text'] = df['headline_text'].apply(remove_sw, args=(stop_words,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z939J1a0gviA",
        "colab_type": "code",
        "outputId": "66b08ab5-1301-4efe-e9ac-3f16773a1d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>str_publish_date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>new_headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030303</td>\n",
              "      <td>unhooked brakes to blame for taiwan train disa...</td>\n",
              "      <td>20030303</td>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>unhooked brakes blame taiwan train disaster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030918</td>\n",
              "      <td>oldest prisoner in tas released citing health</td>\n",
              "      <td>20030918</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>oldest prisoner tas released citing health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030913</td>\n",
              "      <td>nine reportedly dead in portuguese plane crash</td>\n",
              "      <td>20030913</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>nine reportedly dead portuguese plane crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20031031</td>\n",
              "      <td>nurses welcome medicare rebate plan</td>\n",
              "      <td>20031031</td>\n",
              "      <td>2003</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>nurses welcome medicare rebate plan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030930</td>\n",
              "      <td>un cuts its iraq staff</td>\n",
              "      <td>20030930</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>un cuts iraq staff</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date  ...                            new_headline_text\n",
              "0      20030303  ...  unhooked brakes blame taiwan train disaster\n",
              "1      20030918  ...   oldest prisoner tas released citing health\n",
              "2      20030913  ...  nine reportedly dead portuguese plane crash\n",
              "3      20031031  ...          nurses welcome medicare rebate plan\n",
              "4      20030930  ...                           un cuts iraq staff\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWr-Hb-IhWch",
        "colab_type": "code",
        "outputId": "159c8f5a-1346-4206-cf8b-f70187b7137c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Lemmatize and then Stemming data\n",
        "\n",
        "# Here we will upgrade our last function\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer,SnowballStemmer\n",
        "  \n",
        "nltk.download('wordnet')\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer1 = PorterStemmer()\n",
        "stemmer2 = SnowballStemmer('english')\n",
        "\n",
        "def text_cleaner(string_series,stopwords):\n",
        "  \n",
        "  tokens = tokenize(string_series)\n",
        "  no_sw = [w for w in tokens if w not in stopwords]\n",
        "  lemma = [lemmatizer.lemmatize(l) for l in no_sw]\n",
        "  stem = [stemmer2.stem(s) for s in lemma]\n",
        "  result = join_tokens(stem)\n",
        "  return result\n",
        "\n",
        "def tokens_cleaner(string_series,stopwords):\n",
        "  \n",
        "  tokens = tokenize(string_series)\n",
        "  no_sw = [w for w in tokens if w not in stopwords]\n",
        "  lemma = [lemmatizer.lemmatize(l) for l in no_sw]\n",
        "  stem = [stemmer2.stem(s) for s in lemma]\n",
        "  return stem"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDnU4oYi6TTj",
        "colab_type": "code",
        "outputId": "1a7905fc-c0e3-49ab-8bec-5a0bb88dce1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Applying the function\n",
        "\n",
        "df['new_headline_text'] = df['headline_text'].apply(text_cleaner, args=(stop_words,))\n",
        "df['tokens'] = df['headline_text'].apply(tokens_cleaner, args=(stop_words,))\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-yDHk6S7bdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "3fbaaa4a-200d-4933-b216-a7c35d5deb79"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>str_publish_date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>new_headline_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030303</td>\n",
              "      <td>unhooked brakes to blame for taiwan train disa...</td>\n",
              "      <td>20030303</td>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>unhook brake blame taiwan train disast</td>\n",
              "      <td>[unhook, brake, blame, taiwan, train, disast]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030918</td>\n",
              "      <td>oldest prisoner in tas released citing health</td>\n",
              "      <td>20030918</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>oldest prison ta releas cite health</td>\n",
              "      <td>[oldest, prison, ta, releas, cite, health]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030913</td>\n",
              "      <td>nine reportedly dead in portuguese plane crash</td>\n",
              "      <td>20030913</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>nine report dead portugues plane crash</td>\n",
              "      <td>[nine, report, dead, portugues, plane, crash]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20031031</td>\n",
              "      <td>nurses welcome medicare rebate plan</td>\n",
              "      <td>20031031</td>\n",
              "      <td>2003</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>nurs welcom medicar rebat plan</td>\n",
              "      <td>[nurs, welcom, medicar, rebat, plan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030930</td>\n",
              "      <td>un cuts its iraq staff</td>\n",
              "      <td>20030930</td>\n",
              "      <td>2003</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>un cut iraq staff</td>\n",
              "      <td>[un, cut, iraq, staff]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date  ...                                         tokens\n",
              "0      20030303  ...  [unhook, brake, blame, taiwan, train, disast]\n",
              "1      20030918  ...     [oldest, prison, ta, releas, cite, health]\n",
              "2      20030913  ...  [nine, report, dead, portugues, plane, crash]\n",
              "3      20031031  ...           [nurs, welcom, medicar, rebat, plan]\n",
              "4      20030930  ...                         [un, cut, iraq, staff]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fim8KotXmYr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "dictionary = gensim.corpora.Dictionary(df['tokens'].values)\n",
        "\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in df['tokens'].values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I42lkimJW9WM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3ff4d038-215f-4ad4-d017-e71b3c2cfd89"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=12, id2word=dictionary, passes=2, workers=4)\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.031*\"australia\" + 0.024*\"win\" + 0.020*\"world\" + 0.019*\"day\" + 0.014*\"final\" + 0.013*\"open\" + 0.013*\"cup\" + 0.009*\"first\" + 0.009*\"afl\" + 0.009*\"australian\"\n",
            "Topic: 1 Word: 0.028*\"elect\" + 0.014*\"new\" + 0.011*\"bill\" + 0.011*\"vote\" + 0.011*\"labor\" + 0.010*\"senat\" + 0.008*\"say\" + 0.008*\"refuge\" + 0.008*\"challeng\" + 0.008*\"parliament\"\n",
            "Topic: 2 Word: 0.018*\"countri\" + 0.017*\"canberra\" + 0.016*\"fund\" + 0.014*\"govern\" + 0.014*\"new\" + 0.010*\"hope\" + 0.010*\"tasmanian\" + 0.009*\"wa\" + 0.008*\"centr\" + 0.008*\"hill\"\n",
            "Topic: 3 Word: 0.038*\"polic\" + 0.038*\"man\" + 0.023*\"charg\" + 0.022*\"woman\" + 0.021*\"court\" + 0.016*\"murder\" + 0.015*\"crash\" + 0.014*\"face\" + 0.013*\"death\" + 0.012*\"car\"\n",
            "Topic: 4 Word: 0.022*\"rural\" + 0.022*\"nation\" + 0.019*\"health\" + 0.017*\"call\" + 0.013*\"news\" + 0.012*\"park\" + 0.012*\"minist\" + 0.010*\"busi\" + 0.009*\"liber\" + 0.008*\"polit\"\n",
            "Topic: 5 Word: 0.012*\"lead\" + 0.012*\"head\" + 0.011*\"victorian\" + 0.011*\"race\" + 0.011*\"futur\" + 0.010*\"brisban\" + 0.009*\"violenc\" + 0.008*\"western\" + 0.008*\"rail\" + 0.007*\"intern\"\n",
            "Topic: 6 Word: 0.018*\"one\" + 0.014*\"farm\" + 0.013*\"miss\" + 0.013*\"search\" + 0.012*\"port\" + 0.011*\"farmer\" + 0.011*\"royal\" + 0.010*\"weather\" + 0.010*\"famili\" + 0.010*\"hobart\"\n",
            "Topic: 7 Word: 0.028*\"fire\" + 0.019*\"coast\" + 0.019*\"north\" + 0.015*\"market\" + 0.014*\"south\" + 0.013*\"west\" + 0.013*\"queensland\" + 0.013*\"share\" + 0.012*\"school\" + 0.012*\"flood\"\n",
            "Topic: 8 Word: 0.015*\"cut\" + 0.014*\"job\" + 0.013*\"price\" + 0.013*\"rise\" + 0.012*\"rate\" + 0.012*\"say\" + 0.011*\"mine\" + 0.011*\"communiti\" + 0.010*\"abc\" + 0.010*\"turnbul\"\n",
            "Topic: 9 Word: 0.035*\"interview\" + 0.022*\"hour\" + 0.012*\"test\" + 0.012*\"nrl\" + 0.011*\"presid\" + 0.010*\"john\" + 0.010*\"korea\" + 0.010*\"png\" + 0.010*\"dog\" + 0.009*\"told\"\n",
            "Topic: 10 Word: 0.033*\"u\" + 0.017*\"china\" + 0.013*\"say\" + 0.013*\"protest\" + 0.011*\"war\" + 0.011*\"australian\" + 0.008*\"dollar\" + 0.008*\"australia\" + 0.007*\"pm\" + 0.007*\"right\"\n",
            "Topic: 11 Word: 0.026*\"plan\" + 0.023*\"trump\" + 0.022*\"council\" + 0.020*\"chang\" + 0.015*\"water\" + 0.013*\"tasmania\" + 0.010*\"say\" + 0.009*\"public\" + 0.009*\"urg\" + 0.009*\"land\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mApZrSIFhJur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}